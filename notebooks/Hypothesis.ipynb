{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_18728\\1578795113.py:2: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/MachineLearningRating_v3_cleaned.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the original .txt file using the correct separator\n",
    "df = pd.read_csv('../data/MachineLearningRating_v3_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      ",UnderwrittenCoverID        0\n",
      "PolicyID                    0\n",
      "TransactionMonth            0\n",
      "IsVATRegistered             0\n",
      "Citizenship                 0\n",
      "LegalType                   0\n",
      "Title                       0\n",
      "Language                    0\n",
      "Bank                        0\n",
      "AccountType                 0\n",
      "MaritalStatus               0\n",
      "Gender                      0\n",
      "Country                     0\n",
      "Province                    0\n",
      "PostalCode                  0\n",
      "MainCrestaZone              0\n",
      "SubCrestaZone               0\n",
      "ItemType                    0\n",
      "mmcode                      0\n",
      "VehicleType                 0\n",
      "RegistrationYear            0\n",
      "make                        0\n",
      "Model                       0\n",
      "Cylinders                   0\n",
      "cubiccapacity               0\n",
      "kilowatts                   0\n",
      "bodytype                    0\n",
      "NumberOfDoors               0\n",
      "VehicleIntroDate            0\n",
      "AlarmImmobiliser            0\n",
      "TrackingDevice              0\n",
      "CapitalOutstanding          0\n",
      "NewVehicle                  0\n",
      "SumInsured                  0\n",
      "TermFrequency               0\n",
      "CalculatedPremiumPerTerm    0\n",
      "ExcessSelected              0\n",
      "CoverCategory               0\n",
      "CoverType                   0\n",
      "CoverGroup                  0\n",
      "Section                     0\n",
      "Product                     0\n",
      "StatutoryClass              0\n",
      "StatutoryRiskType           0\n",
      "TotalPremium                0\n",
      "TotalClaims                 0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of missing values per column:\n",
      ",UnderwrittenCoverID        0.0\n",
      "PolicyID                    0.0\n",
      "TransactionMonth            0.0\n",
      "IsVATRegistered             0.0\n",
      "Citizenship                 0.0\n",
      "LegalType                   0.0\n",
      "Title                       0.0\n",
      "Language                    0.0\n",
      "Bank                        0.0\n",
      "AccountType                 0.0\n",
      "MaritalStatus               0.0\n",
      "Gender                      0.0\n",
      "Country                     0.0\n",
      "Province                    0.0\n",
      "PostalCode                  0.0\n",
      "MainCrestaZone              0.0\n",
      "SubCrestaZone               0.0\n",
      "ItemType                    0.0\n",
      "mmcode                      0.0\n",
      "VehicleType                 0.0\n",
      "RegistrationYear            0.0\n",
      "make                        0.0\n",
      "Model                       0.0\n",
      "Cylinders                   0.0\n",
      "cubiccapacity               0.0\n",
      "kilowatts                   0.0\n",
      "bodytype                    0.0\n",
      "NumberOfDoors               0.0\n",
      "VehicleIntroDate            0.0\n",
      "AlarmImmobiliser            0.0\n",
      "TrackingDevice              0.0\n",
      "CapitalOutstanding          0.0\n",
      "NewVehicle                  0.0\n",
      "SumInsured                  0.0\n",
      "TermFrequency               0.0\n",
      "CalculatedPremiumPerTerm    0.0\n",
      "ExcessSelected              0.0\n",
      "CoverCategory               0.0\n",
      "CoverType                   0.0\n",
      "CoverGroup                  0.0\n",
      "Section                     0.0\n",
      "Product                     0.0\n",
      "StatutoryClass              0.0\n",
      "StatutoryRiskType           0.0\n",
      "TotalPremium                0.0\n",
      "TotalClaims                 0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df.isna().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Check the percentage of missing values\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "print(\"\\nPercentage of missing values per column:\")\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",UnderwrittenCoverID        0\n",
      "PolicyID                    0\n",
      "TransactionMonth            0\n",
      "IsVATRegistered             0\n",
      "Citizenship                 0\n",
      "LegalType                   0\n",
      "Title                       0\n",
      "Language                    0\n",
      "Bank                        0\n",
      "AccountType                 0\n",
      "MaritalStatus               0\n",
      "Gender                      0\n",
      "Country                     0\n",
      "Province                    0\n",
      "PostalCode                  0\n",
      "MainCrestaZone              0\n",
      "SubCrestaZone               0\n",
      "ItemType                    0\n",
      "mmcode                      0\n",
      "VehicleType                 0\n",
      "RegistrationYear            0\n",
      "make                        0\n",
      "Model                       0\n",
      "Cylinders                   0\n",
      "cubiccapacity               0\n",
      "kilowatts                   0\n",
      "bodytype                    0\n",
      "NumberOfDoors               0\n",
      "VehicleIntroDate            0\n",
      "AlarmImmobiliser            0\n",
      "TrackingDevice              0\n",
      "CapitalOutstanding          0\n",
      "NewVehicle                  0\n",
      "SumInsured                  0\n",
      "TermFrequency               0\n",
      "CalculatedPremiumPerTerm    0\n",
      "ExcessSelected              0\n",
      "CoverCategory               0\n",
      "CoverType                   0\n",
      "CoverGroup                  0\n",
      "Section                     0\n",
      "Product                     0\n",
      "StatutoryClass              0\n",
      "StatutoryRiskType           0\n",
      "TotalPremium                0\n",
      "TotalClaims                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify if all missing values are handled\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: Index(['PolicyID', 'PostalCode', 'mmcode', 'RegistrationYear', 'Cylinders',\n",
      "       'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'CapitalOutstanding',\n",
      "       'SumInsured', 'CalculatedPremiumPerTerm', 'TotalPremium',\n",
      "       'TotalClaims'],\n",
      "      dtype='object')\n",
      "\n",
      "Outliers in PolicyID:\n",
      "Number of outliers: 31232\n",
      "Percentage of outliers: 3.12%\n",
      "count    31232.000000\n",
      "mean     21730.691246\n",
      "std        425.654385\n",
      "min      20943.000000\n",
      "25%      21353.000000\n",
      "50%      21648.500000\n",
      "75%      22223.000000\n",
      "max      22223.000000\n",
      "Name: PolicyID, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in PostalCode:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: PostalCode, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in mmcode:\n",
      "Number of outliers: 241622\n",
      "Percentage of outliers: 24.16%\n",
      "count    2.416220e+05\n",
      "mean     3.865663e+07\n",
      "std      2.037023e+07\n",
      "min      5.036102e+06\n",
      "25%      2.284015e+07\n",
      "50%      4.400462e+07\n",
      "75%      6.002737e+07\n",
      "max      6.408230e+07\n",
      "Name: mmcode, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in RegistrationYear:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: RegistrationYear, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in Cylinders:\n",
      "Number of outliers: 33708\n",
      "Percentage of outliers: 3.37%\n",
      "count    33708.000000\n",
      "mean         5.378575\n",
      "std          0.485039\n",
      "min          5.000000\n",
      "25%          5.000000\n",
      "50%          5.000000\n",
      "75%          6.000000\n",
      "max          6.000000\n",
      "Name: Cylinders, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in cubiccapacity:\n",
      "Number of outliers: 54402\n",
      "Percentage of outliers: 5.44%\n",
      "count    54402.000000\n",
      "mean      1390.352597\n",
      "std         88.895520\n",
      "min       1298.000000\n",
      "25%       1298.000000\n",
      "50%       1330.000000\n",
      "75%       1495.000000\n",
      "max       1499.000000\n",
      "Name: cubiccapacity, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in kilowatts:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: kilowatts, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in NumberOfDoors:\n",
      "Number of outliers: 106797\n",
      "Percentage of outliers: 10.68%\n",
      "count    106797.000000\n",
      "mean          4.203405\n",
      "std           1.321585\n",
      "min           2.000000\n",
      "25%           2.000000\n",
      "50%           5.000000\n",
      "75%           5.000000\n",
      "max           5.000000\n",
      "Name: NumberOfDoors, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in CapitalOutstanding:\n",
      "Number of outliers: 207039\n",
      "Percentage of outliers: 20.70%\n",
      "count    207039.000000\n",
      "mean     249234.877782\n",
      "std       80956.997642\n",
      "min           1.000000\n",
      "25%      198900.000000\n",
      "50%      250000.000000\n",
      "75%      320000.000000\n",
      "max      387000.000000\n",
      "Name: CapitalOutstanding, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in SumInsured:\n",
      "Number of outliers: 104294\n",
      "Percentage of outliers: 10.43%\n",
      "count    1.042940e+05\n",
      "mean     4.992551e+06\n",
      "std      1.744789e+05\n",
      "min      6.250000e+05\n",
      "25%      5.000000e+06\n",
      "50%      5.000000e+06\n",
      "75%      5.000000e+06\n",
      "max      5.000000e+06\n",
      "Name: SumInsured, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in CalculatedPremiumPerTerm:\n",
      "Number of outliers: 175508\n",
      "Percentage of outliers: 17.55%\n",
      "count    175508.000000\n",
      "mean        513.224217\n",
      "std         239.462968\n",
      "min         220.195100\n",
      "25%         296.915500\n",
      "50%         432.559700\n",
      "75%         713.516000\n",
      "max         980.670200\n",
      "Name: CalculatedPremiumPerTerm, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in TotalPremium:\n",
      "Number of outliers: 208911\n",
      "Percentage of outliers: 20.89%\n",
      "count    208911.000000\n",
      "mean        271.135836\n",
      "std         224.812387\n",
      "min          54.844925\n",
      "25%          78.947368\n",
      "50%         198.521404\n",
      "75%         380.926053\n",
      "max         778.698158\n",
      "Name: TotalPremium, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Outliers in TotalClaims:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: TotalClaims, dtype: float64\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"Numerical columns:\", numeric_columns)\n",
    "def identify_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "for column in numeric_columns:\n",
    "    outliers = identify_outliers(df, column)\n",
    "    print(f\"\\nOutliers in {column}:\")\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "    print(f\"Percentage of outliers: {(len(outliers) / len(df)) * 100:.2f}%\")\n",
    "    print(outliers[column].describe())\n",
    "    print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_clean = ['cubiccapacity', 'kilowatts', 'CapitalOutstanding', 'SumInsured', 'CalculatedPremiumPerTerm', 'TotalPremium', 'TotalClaims']\n",
    "def cap_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = df[column].clip(lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "df_capped = df.copy()\n",
    "for col in columns_to_clean:\n",
    "    df_capped = cap_outliers(df_capped, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_clean = ['cubiccapacity', 'kilowatts', 'CapitalOutstanding', 'SumInsured', 'CalculatedPremiumPerTerm', 'TotalPremium', 'TotalClaims']\n",
    "\n",
    "# Function to identify outliers\n",
    "def identify_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "# Function to cap outliers (Winsorization)\n",
    "def cap_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = df[column].clip(lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "# Create cleaned dataframe by capping outliers\n",
    "df_cleaned = df.copy()\n",
    "for column in columns_to_clean:\n",
    "    df_cleaned = cap_outliers(df_cleaned, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining outliers in cubiccapacity:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "Remaining outliers in kilowatts:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "Remaining outliers in CapitalOutstanding:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "Remaining outliers in SumInsured:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "Remaining outliers in CalculatedPremiumPerTerm:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "Remaining outliers in TotalPremium:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "Remaining outliers in TotalClaims:\n",
      "Number of outliers: 0\n",
      "Percentage of outliers: 0.00%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def check_remaining_outliers(df, columns):\n",
    "    for column in columns:\n",
    "        outliers = identify_outliers(df, column)\n",
    "        print(f\"\\nRemaining outliers in {column}:\")\n",
    "        print(f\"Number of outliers: {len(outliers)}\")\n",
    "        print(f\"Percentage of outliers: {(len(outliers) / len(df)) * 100:.2f}%\")\n",
    "        if len(outliers) > 0:\n",
    "            print(outliers[column].describe())\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "check_remaining_outliers(df_cleaned, columns_to_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment data into Group A (Control Group) and Group B (Test Group) for Provinces\n",
    "groupA = df[df['Province'] == 'Gauteng']  # Replace with actual province name\n",
    "groupB = df[df['Province'] == 'Western Cape']  # Replace with actual province name\n",
    "\n",
    "# Optionally, check for statistical equivalence between groups on other features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not specified' 'Male' 'Female']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the Gender column\n",
    "unique_genders = df['Gender'].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1459 1513 1619 1625 1629 1852 1982 2007 2066 4093 2000 1577 1610 2410\n",
      "  122 1520 1709 1739 4000 4091 4342 4359 7784  970 6213 6390 1868 4310\n",
      "  309  152  181 1821 4449 4037  139 4074 1057 7100 8566 1863 1875 2001\n",
      " 2091 3170 3950 1021 2380  300  302  458 7750  157 4811 4930 5000 5090\n",
      " 5160 5219 5410 5920 6025 6139 5040 6200 6201 6212   22   64   84  162\n",
      "  164 8000  182  183  186  190 5326  192  194  199  200  208  258  264\n",
      " 1431 1441 1455 1494 1496  284 1507 1540 1571 1724 1754 1757 1759 1779\n",
      " 1803 1804 1806 1809 1818 1828 1830 1862 1864 1865 1984 2014 2019 2021\n",
      " 2090 2188 2198 3180 3200 3245 3310 3380 3609 3610 3612 3613 3600 3629\n",
      " 3630 3650 3780 3900 3934 3973 5143 3880 3882 3915 4001 4004 4011 4023\n",
      " 4027 4051 4052 4053 4056 4057 4059 4060 4061 4063 4066 4071 4089 4092\n",
      " 4105 4110 4111 4126 4137 4140 4180 4200 4240 4260 4309 4340 4360 4450\n",
      " 4700  530  556  607  699  738  827 1022 1123 1133 2375 2415 2499 4068\n",
      " 2951 2952 3602 4182 4490 1030  250  299  308  316  335  404  407  322\n",
      "  472 8345 6705 6708 6835 2744 7130 7140 7160 7441 7455 7490 7500 7570\n",
      " 7405 7571 7580 7620 7655 7764 7780 7785 7786 7793 3910 7806 7888 7941\n",
      " 7945 1980  902 4820 5100 5120 5201 5247 6140 6231 6500  118  120  147\n",
      "  161 7460  177 7646  179  184  198 1458 1491 1541 1550 1666 1682 1751\n",
      " 1841 1860 1884 1939  331  303  338 2620 7925 2061 7947 2094 2128 2194\n",
      " 3290 3370 3635 4100 4275 4339 4454  555  628  700  742  812  942 1020\n",
      " 1059 1060 1061 1085 4058  310  314  318  400  450  456  470  479 2531\n",
      " 2865 2876 8160 8190 6838 6875 7195 7437 7501 7503 7600 8020 8051 5252\n",
      " 5319 5670 6059 6211 6242 5321 5600   29  125  153  168  172  269 1426\n",
      " 1449 1454 1462 1475 1559 1575 1632 1640 1740 1811 1813 1835 1874 1928\n",
      " 1940 1947 1949 2069 2070 2092 2190 2192 2195 2940 3201 3217 3607 3680\n",
      " 3700 3750 3802 3815 3855 7350 4069 4070 4084 4099 4133 4145 4380 4470\n",
      "  557  561  608  609  623  690  727  739  745  746  821  951 1024 1035\n",
      " 1047 1050 1053 1062 1098 1365  311  320  333  360  362  370  382  449\n",
      "  457  459  473  474 2502 2574 2610 2740 2840 2841 2860 2868 2869 2890\n",
      " 8149 8301 8309 8530 6600 6848 7101 7220 7525 7550 7690 7783 7800 8001\n",
      " 2920 4810 5070 5099 5130 5180 5480 5601 5611 5900 6229  116  277 1424\n",
      " 1548  305 1745 1805 1812 1900 1948 1983 2040 2093 2170 3000 3306 3616\n",
      " 3652 3965 3350 4019 4148 4400 4457 4491 4730  600  982 1026 1027 1034\n",
      " 1055 1120 1280 1342 2735 2745 2881 7103 7439 7493 7788 7975 8060 4960\n",
      " 5050 5140 5320 5322 5380 5608 6105   31   37   81  112  121  149  154\n",
      "  201  268 1401 1405 1423 1425 1460 7782 1471 1560 1570 1618 1685 1700\n",
      " 1710 1781 1820 1930 1932 1747 2056 2196 2930 3257 3615 3925 3969 4008\n",
      " 4030 4065 4094 4132 4150 4220 2055 4399 4680  708  748  920 1039 1064\n",
      " 1072 1150 1389  301 4125  355  365  379  465  467  476 2870 8165 8446\n",
      " 6506 7000 7133 7406 7581 7700 7751 8017 4800 5170 5500 5700 6000 6001\n",
      " 6205   35   66 1457 1501 1693 1774 1819 1824 1827 1837 2017 3105 3276\n",
      " 3297 3381 3920 4144 4170  617  925  950  993 1054 1124 1126 1245 2420\n",
      "  380  414  422  475 2500 2534 2754 2791 8170 6571 7310 7380 7442 7530\n",
      " 7612 7745 7755 8040 5185 3135 4401  939 6280  151 1466 1519 1725 1791\n",
      " 2143 2197 3624 4031 4062 4075 4270 4302 4319  631  743  790 1003 1023\n",
      " 1372 2351  337 2880 2882 7200 7569 7801 8005 5365 1630 1851 1867 2008\n",
      " 3010 3203 3670 4691  737 1250  477 7144 4990 5209 5660 5720   54  129\n",
      "  187  195  220 1687 1742 1834 1963 2189 3080 3150 3250 3837 3838 3865\n",
      " 3887 3935 3968 4250  751  931 1000 1038 1129 2230  292  317  399  431\n",
      "  469  485  486 2835 8271 8447 6570 7340 7532 7626 4980 4430 7456 5470\n",
      " 6241   44 6720  193  196 1474 1861 2018 2063 2095 2191 3651 4405 6810\n",
      " 1058  453  495 2571 2619 8306 6625 7802  356  984 5253 5362 5435 5455\n",
      "  101  143  175 1448 1743 1801 1869 2028 3242 3270  721  736  802  945\n",
      " 1240 2231  307  351  388 2507 1829 1914 6350 6120 1421 1154  325 7540\n",
      " 2470 6850 4480 1631 1688 3107 3300 1052 7395 7463 7789 4184 2570 1794\n",
      " 1833 8240 1185 6840 5687  807 2057 1127 7579  132 3742 3660 1692 2157\n",
      " 4171 8460 2210 2031 7560 4067 2037 1522 3655 2193 7798 2062 3740 3830\n",
      " 4016  371 7763  286  402 6070   46 4025  462  466 2766 7450  430 1744\n",
      " 4087 3974 4455 7582 7280 7790 7583  510 6836 4005 2530  621 7760 1748\n",
      " 1665 2125 7766  340 6655]\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the PostalCode column\n",
    "unique_postal_codes = df['PostalCode'].unique()\n",
    "print(unique_postal_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_9840\\2380098913.py:2: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/MachineLearningRating_v3_cleaned.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/MachineLearningRating_v3_cleaned.csv')\n",
    "\n",
    "# Segment by provinces (example: Gauteng vs Western Cape)\n",
    "groupA_province = df[df['Province'] == 'Gauteng']['TotalClaims']\n",
    "groupB_province = df[df['Province'] == 'Western Cape']['TotalClaims']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment by zip codes (example: postal code 1001 vs 2001)\n",
    "groupA_zip = df[df['PostalCode'] == 7560]['TotalClaims']\n",
    "groupB_zip = df[df['PostalCode'] == 4067]['TotalClaims']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_9840\\3591641343.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalPremium'].fillna(0, inplace=True)\n",
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_9840\\3591641343.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalClaims'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Convert TotalPremium and TotalClaims to numeric (force non-numeric values to NaN)\n",
    "df['TotalPremium'] = pd.to_numeric(df['TotalPremium'], errors='coerce')\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce')\n",
    "\n",
    "# Optionally, handle NaN values (choose your method)\n",
    "# You can fill NaNs with 0 or with the mean, depending on your case\n",
    "df['TotalPremium'].fillna(0, inplace=True)\n",
    "df['TotalClaims'].fillna(0, inplace=True)\n",
    "\n",
    "# Now, perform the subtraction for margin differences\n",
    "groupA_margin = df[df['PostalCode'] == 7560]['TotalPremium'] - df[df['PostalCode'] == 7560]['TotalClaims']\n",
    "groupB_margin = df[df['PostalCode'] == 4067]['TotalPremium'] - df[df['PostalCode'] == 4067]['TotalClaims']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment by gender for risk differences\n",
    "groupA_gender = df[df['Gender'] == 'Female']['TotalClaims']\n",
    "groupB_gender = df[df['Gender'] == 'Male']['TotalClaims']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_9840\\123321415.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalPremium'].fillna(0, inplace=True)\n",
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_9840\\123321415.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalClaims'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for risk differences across provinces: 0.15541895767348024\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Convert relevant columns to numeric, forcing invalid parsing to NaN\n",
    "df['TotalPremium'] = pd.to_numeric(df['TotalPremium'], errors='coerce')\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce')\n",
    "\n",
    "# Handle NaN values (you can use different strategies like dropping or filling with mean/median)\n",
    "df['TotalPremium'].fillna(0, inplace=True)\n",
    "df['TotalClaims'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate risk (you can define risk as the difference between TotalPremium and TotalClaims)\n",
    "df['Risk'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "# Segment by provinces (replace with actual province names)\n",
    "groupA_province = df[df['Province'] == 'Gauteng']['Risk']\n",
    "groupB_province = df[df['Province'] == 'Western Cape']['Risk']\n",
    "\n",
    "# Ensure both groups are numeric (this should already be covered above but double-check)\n",
    "groupA_province = pd.to_numeric(groupA_province, errors='coerce')\n",
    "groupB_province = pd.to_numeric(groupB_province, errors='coerce')\n",
    "\n",
    "# Perform the t-test for risk differences between provinces\n",
    "t_stat_province, p_value_province = ttest_ind(groupA_province, groupB_province, nan_policy='omit')\n",
    "\n",
    "print(f\"p-value for risk differences across provinces: {p_value_province}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for risk differences between zip codes: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_9840\\1098636950.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalPremium'].fillna(0, inplace=True)\n",
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_9840\\1098636950.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['TotalClaims'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Convert 'TotalPremium' and 'TotalClaims' to numeric values, forcing invalid values to NaN\n",
    "df['TotalPremium'] = pd.to_numeric(df['TotalPremium'], errors='coerce')\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce')\n",
    "\n",
    "# Fill NaN values (here using 0 as an example, but you can use mean/median if preferred)\n",
    "df['TotalPremium'].fillna(0, inplace=True)\n",
    "df['TotalClaims'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the risk (difference between TotalPremium and TotalClaims)\n",
    "df['Risk'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "# Segment by zip codes (replace with actual zip codes)\n",
    "groupA_zip = df[df['PostalCode'] == 7560]['Risk']\n",
    "groupB_zip = df[df['PostalCode'] == 4067]['Risk']\n",
    "\n",
    "# Ensure both groups are numeric (convert to numeric again to be sure)\n",
    "groupA_zip = pd.to_numeric(groupA_zip, errors='coerce')\n",
    "groupB_zip = pd.to_numeric(groupB_zip, errors='coerce')\n",
    "\n",
    "# Handle NaN values in both groups by omitting them\n",
    "groupA_zip = groupA_zip.dropna()\n",
    "groupB_zip = groupB_zip.dropna()\n",
    "\n",
    "# Perform the t-test for risk differences between zip codes\n",
    "t_stat_zip, p_value_zip = ttest_ind(groupA_zip, groupB_zip, nan_policy='omit')\n",
    "\n",
    "print(f\"p-value for risk differences between zip codes: {p_value_zip}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for margin differences between zip codes: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Perform t-test for margin differences between zip codes\n",
    "t_stat_margin, p_value_margin = ttest_ind(groupA_margin, groupB_margin)\n",
    "print(f\"p-value for margin differences between zip codes: {p_value_margin}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for risk differences between Women and Men: 0.8041073961270343\n"
     ]
    }
   ],
   "source": [
    "# Perform t-test for risk differences between genders\n",
    "t_stat_gender, p_value_gender = ttest_ind(groupA_gender, groupB_gender)\n",
    "print(f\"p-value for risk differences between Women and Men: {p_value_gender}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to reject the null hypothesis for Risk Differences Across Provinces.\n",
      "Reject the null hypothesis for Risk Differences Between Zip Codes.\n",
      "Reject the null hypothesis for Margin Differences Between Zip Codes.\n",
      "Fail to reject the null hypothesis for Risk Differences Between Women and Men.\n"
     ]
    }
   ],
   "source": [
    "def analyze_p_value(p_value, hypothesis_name):\n",
    "    if p_value < 0.05:\n",
    "        print(f\"Reject the null hypothesis for {hypothesis_name}.\")\n",
    "    else:\n",
    "        print(f\"Fail to reject the null hypothesis for {hypothesis_name}.\")\n",
    "\n",
    "# Analyze all hypotheses\n",
    "analyze_p_value(p_value_province, \"Risk Differences Across Provinces\")\n",
    "analyze_p_value(p_value_zip, \"Risk Differences Between Zip Codes\")\n",
    "analyze_p_value(p_value_margin, \"Margin Differences Between Zip Codes\")\n",
    "analyze_p_value(p_value_gender, \"Risk Differences Between Women and Men\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanu\\AppData\\Local\\Temp\\ipykernel_18728\\2138467552.py:5: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/MachineLearningRating_v3_cleaned.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table for Provinces and ClaimMade:\n",
      "ClaimMade       False  True \n",
      "Province                    \n",
      "Eastern Cape    30330      6\n",
      "Free State       8088     11\n",
      "Gauteng        392543   1322\n",
      "KwaZulu-Natal  169298    483\n",
      "Limpopo         24769     67\n",
      "Mpumalanga      52590    128\n",
      "North West     142938    349\n",
      "Northern Cape    6372      8\n",
      "Western Cape   170430    366\n",
      "\n",
      "Chi-Square Statistic for Provinces: 167.08117743413868\n",
      "p-value: 5.272438857224102e-32\n",
      "Degrees of Freedom: 8\n",
      "Expected Frequencies:\n",
      "[[3.02528875e+04 8.31124950e+01]\n",
      " [8.07681091e+03 2.21890855e+01]\n",
      " [3.92785916e+05 1.07908435e+03]\n",
      " [1.69315846e+05 4.65154355e+02]\n",
      " [2.47679560e+04 6.80439717e+01]\n",
      " [5.25735668e+04 1.44433166e+02]\n",
      " [1.42894432e+05 3.92567908e+02]\n",
      " [6.36252051e+03 1.74794870e+01]\n",
      " [1.70328065e+05 4.67935182e+02]]\n",
      "\n",
      "There are significant risk differences across provinces (reject the null hypothesis).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('../data/MachineLearningRating_v3_cleaned.csv')\n",
    "\n",
    "# Convert 'TotalClaims' to numeric, forcing errors to NaN and then fill NaNs with 0\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce').fillna(0)\n",
    "\n",
    "# Create a new column to categorize whether a claim is made or not\n",
    "df['ClaimMade'] = df['TotalClaims'] > 0\n",
    "\n",
    "# Generate a contingency table for 'Province' and 'ClaimMade'\n",
    "contingency_table_provinces = pd.crosstab(df['Province'], df['ClaimMade'])\n",
    "\n",
    "print(\"Contingency Table for Provinces and ClaimMade:\")\n",
    "print(contingency_table_provinces)\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_provinces, p_provinces, dof_provinces, expected_provinces = chi2_contingency(contingency_table_provinces)\n",
    "\n",
    "print(f\"\\nChi-Square Statistic for Provinces: {chi2_provinces}\")\n",
    "print(f\"p-value: {p_provinces}\")\n",
    "print(f\"Degrees of Freedom: {dof_provinces}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected_provinces)\n",
    "\n",
    "# Interpret the result\n",
    "if p_provinces < 0.05:\n",
    "    print(\"\\nThere are significant risk differences across provinces (reject the null hypothesis).\")\n",
    "else:\n",
    "    print(\"\\nThere are no significant risk differences across provinces (fail to reject the null hypothesis).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table for Zip Codes and ClaimMade:\n",
      "ClaimMade    False  True \n",
      "PostalCode               \n",
      "122          48961    210\n",
      "299          25479     67\n",
      "2000        133012    486\n",
      "7405         18489     29\n",
      "7784         28535     50\n",
      "\n",
      "Chi-Square Statistic for Zip Codes: 60.22649731769842\n",
      "p-value: 2.5997263446847924e-12\n",
      "Degrees of Freedom: 4\n",
      "Expected Frequencies:\n",
      "[[4.90088415e+04 1.62158493e+02]\n",
      " [2.54617532e+04 8.42468294e+01]\n",
      " [1.33057744e+05 4.40256135e+02]\n",
      " [1.84569304e+04 6.10695525e+01]\n",
      " [2.84907310e+04 9.42689900e+01]]\n",
      "\n",
      "There are significant risk differences between zip codes (reject the null hypothesis).\n",
      "Contingency Table for Gender and ClaimMade:\n",
      "ClaimMade       False  True \n",
      "Gender                      \n",
      "Female           6741     14\n",
      "Male            42723     94\n",
      "Not specified  947894   2632\n",
      "\n",
      "Chi-Square Statistic for Gender: 6.04191188477959\n",
      "p-value: 0.048754589499511086\n",
      "Degrees of Freedom: 2\n",
      "Expected Frequencies:\n",
      "[[6.73649311e+03 1.85068863e+01]\n",
      " [4.26996929e+04 1.17307084e+02]\n",
      " [9.47921814e+05 2.60418603e+03]]\n",
      "\n",
      "There are significant risk differences between Women and Men (reject the null hypothesis).\n"
     ]
    }
   ],
   "source": [
    "# Convert 'TotalClaims' to numeric, forcing errors to NaN and then fill NaNs with 0\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce').fillna(0)\n",
    "\n",
    "# Create a new column to categorize whether a claim is made or not\n",
    "df['ClaimMade'] = df['TotalClaims'] > 0\n",
    "\n",
    "# For risk differences between zip codes, filter top zip codes\n",
    "top_zip_codes = df['PostalCode'].value_counts().nlargest(5).index\n",
    "df_top_zip = df[df['PostalCode'].isin(top_zip_codes)]\n",
    "\n",
    "# Generate a contingency table for 'PostalCode' and 'ClaimMade'\n",
    "contingency_table_zip = pd.crosstab(df_top_zip['PostalCode'], df_top_zip['ClaimMade'])\n",
    "\n",
    "print(\"Contingency Table for Zip Codes and ClaimMade:\")\n",
    "print(contingency_table_zip)\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_zip, p_zip, dof_zip, expected_zip = chi2_contingency(contingency_table_zip)\n",
    "\n",
    "print(f\"\\nChi-Square Statistic for Zip Codes: {chi2_zip}\")\n",
    "print(f\"p-value: {p_zip}\")\n",
    "print(f\"Degrees of Freedom: {dof_zip}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected_zip)\n",
    "\n",
    "# Interpret the result\n",
    "if p_zip < 0.05:\n",
    "    print(\"\\nThere are significant risk differences between zip codes (reject the null hypothesis).\")\n",
    "else:\n",
    "    print(\"\\nThere are no significant risk differences between zip codes (fail to reject the null hypothesis).\")\n",
    "\n",
    "# For risk differences between gender\n",
    "contingency_table_gender = pd.crosstab(df['Gender'], df['ClaimMade'])\n",
    "\n",
    "print(\"Contingency Table for Gender and ClaimMade:\")\n",
    "print(contingency_table_gender)\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_gender, p_gender, dof_gender, expected_gender = chi2_contingency(contingency_table_gender)\n",
    "\n",
    "print(f\"\\nChi-Square Statistic for Gender: {chi2_gender}\")\n",
    "print(f\"p-value: {p_gender}\")\n",
    "print(f\"Degrees of Freedom: {dof_gender}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected_gender)\n",
    "\n",
    "# Interpret the result\n",
    "if p_gender < 0.05:\n",
    "    print(\"\\nThere are significant risk differences between Women and Men (reject the null hypothesis).\")\n",
    "else:\n",
    "    print(\"\\nThere are no significant risk differences between Women and Men (fail to reject the null hypothesis).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
